{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350b57ef",
   "metadata": {},
   "source": [
    "# 1. Introdução às Redes Neurais (RNs)\n",
    "\n",
    "Algumas aplicações de RNs:\n",
    "\n",
    "* Reconhecimento Facial\n",
    "* Encontrar soluções para controle de tráfego\n",
    "* Carros Autônomos\n",
    "* etc...\n",
    "\n",
    "Uma Rede Neural se adapta ao ambiente, em problemas que não existe um algoritmo pré-determinado para resolvê-los (sistemas de recomendação, buscas, grafos, ordenações, etc). Utilizada quando se tem muitos dados (ex. *Big Data*) e problemas complexos. A ideia é se basear no funcionamento do sistema neural humano no processo de aprendizagem - uma pequena abstração de como funciona a troca de informações no cérebro humano.\n",
    "\n",
    "Com técnicas de *Deep Learning*, as RNs ficaram populares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef9d732",
   "metadata": {},
   "source": [
    "## 1.1 Fundamentos Biológicos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61123bfb",
   "metadata": {},
   "source": [
    "A Figura 1, mostra um neurônio humano que é pelo qual um neurônio artificial se baseia.\n",
    "\n",
    "| ![neuronio](img/partes-do-neuronio.jpg) |\n",
    "|:--:|\n",
    "| <b>Figura 1 - Anatomia de um Neurônio.</b>|\n",
    "\n",
    "* **Neurônios:** o cérebro usa para processar informações\n",
    "* **Axônio:** transmite o sinal de um neurônio para outro (sinais elétricos, sinapses) - conecta os neurônios.\n",
    "\n",
    "Substâncias químicas são lançadas das sinapses (ligação de um neurônio com outro) e entram pelos dentritos, aumentando ou baixando o potencial elétrico do corpo da célula. É baseado nesse potencial elétrico que uma RN vai tomar uma decisão. Se o valor for muito alto ele ativa o neurônio. Se for muito baixo, não ativa o neurônio. Dessa forma, o neurônio dispara se a entrada é maior que um número definido (é basicamente liga ou não liga). Por exemplo, supomos que o valor é 1. Se o valor for igual a 1 ele liga, se for menor, não dispara o neurônio.\n",
    "\n",
    "Quanto às Redes Neurais (formada por vários neurônios), é fornecido um valor de entrada, a rede processa e retorna uma resposta. O neurônio é ativado **se e somente se** o valor for maior que um limiar. Temos então uma **entrada** de dados, os **neurônios** e **axônios** (conecta os neurônios) e é por meio da conexão entre os neurônios que acontece o processo de aprendizagem. É por meio dessa interação entre neurônios e axônios que é gerada uma **saída** que é a resposta da rede."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294ab6c1",
   "metadata": {},
   "source": [
    "## 1.2 Neurônio Artificial\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acd05bc",
   "metadata": {},
   "source": [
    "Veremos nessa subseção como um Neurônio Artificial funciona.\n",
    "É por meio do axônio que as informações vão trafegar. As sinapses são as informações que estão entrando e trafegando dentro deste neurônio.\n",
    "\n",
    "A Figura 2 mostra uma representação bastante simples, dada por Frank Rosemblatt (1958) de uma rede neural, chamada de Perceptron. O nuerônio artificial possui alguns componentes:\n",
    "\n",
    "* **Entradas (*Input*):** $x_1, x_2, \\dots, x_m$, que são em quantidade indeterminada de entradas, ou seja, não é um número fixo.\n",
    "* **Pesos (*Weight*):** $\\omega_1, \\omega_2, \\dots, \\omega_m$, em que cada uma das $m$ entradas tem um peso associado.\n",
    "* **Função Soma:** dada por $\\sum_{i=1}^{m} x_i \\times \\omega_i = x_1\\times \\omega_1 + x_2 \\times \\omega_2 \\dots x_m \\times \\omega_m$\n",
    "* **Função Ativação** \n",
    "\n",
    "\n",
    "| ![rede-neural](img/rede-neural.jpeg) |\n",
    "|:--:|\n",
    "| <b>Figura 2 - Representação básica de uma Rede Neural (modelo Perceptron).</b>|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a671e",
   "metadata": {},
   "source": [
    "## 1.3 Perceptron de uma camada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0a2825",
   "metadata": {},
   "source": [
    "A Figura 3 mostra um exemplo prático de uma rede neural. Os valores da camada de entrada são numéricos e seus respectivos pesos.\n",
    "\n",
    "| ![exemplo-rede-neural](img/perceptron.png) |\n",
    "|:--:|\n",
    "| <b>Figura 3 - Exemplo prático de uma rede neural.</b>|\n",
    "\n",
    "É feita a aplicação da **função soma**, que é bastante simples, somando o valor de cada entrada multiplicada pelo seu respectivo peso. Temos também a **Step function (ou função degrau)** que, dado o valor da soma e passa para essa função e vai dizer se o neurônio foi ativado ou não. Neste exemplo, se o valor retornado for maior do que zero, será igual a 1 e o neurônio ativado. Caso contrário, será igual a 0, portanto, não sendo ativado.\n",
    "\n",
    "A Figura 4 representa graficamente da *Step function* utilizada neste exemplo. Note que os valores da linha reta são 1 ou 0.\n",
    "\n",
    "| ![step-function](img/step-function.png) |\n",
    "|:--:|\n",
    "| <b>Figura 4 - Representação gráfica da *Step function*.</b>|\n",
    "\n",
    "\n",
    "Caso temos um peso positivo, a sinapse é chamada de **sinapse excitadora**, que é justamente a idéia de aumentar o potencial elétrico do corpo da célula. Ou seja, o peso positivo tem um maior potencial para ativar o neurônio. Caso contrário, com peso negativo, temos a **sinapse inibidora**, que está diminuindo o potencial de ativação do neurônio. Os pesos são as sinapses, que amplificam ou reduzem o sinal de entrada. Dessa forma, **o conhecimento da rede neural são os pesos**. Então, o que ela vai aprender será o melhor conjunto de pesos para uma determinada base de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4019c683",
   "metadata": {},
   "source": [
    "### 1.3.1 Implementação do Perceptron de uma camada\n",
    "\n",
    "Como pode ser visto a seguir, é uma implementação bastante simples do perceptron mostrado na Figura 3.\n",
    "Temos que tratar os erros. Com isso, é necessário fazer o ajuste de pesos para diminuir os erros.\n",
    "O algoritmo mais simples para calcular o erro é:\n",
    "\n",
    "$$erro = respostaCorreta - respostaCalculada$$\n",
    "\n",
    "Os pesos são atualizados até os erros serem pequenos:\n",
    "\n",
    "$$peso(n+1) = peso(n) + (taxaAprendizagem \\times entrada \\times erro)$$\n",
    "\n",
    "Em que $peso(n)$ é o valor do peso atual e $peso(n+1)$ é o valor do novo peso. A taxa de aprendizagem é uma valor fixo definido que indica o quanto que a rede vai aprender, ou seja, o quanto que os pesos vão avançar. Os pesos da rede são alterados para esses valores e o processo é repetido novamente, calculando os acertos e os erros até que consiga chegar em pesos que os registros sejam classificados corretamente. Precisamos ter uma função que **minimize** o valor do erro.\n",
    "\n",
    "Ressaltando que o conhecimento em uma Rede Neural se dá pelos pesos que se encontra para cada atributo. A base de dados utilizada na implementação é a do **Operador E**, que pode ser visto na tabela a seguir.\n",
    "\n",
    "| x1 | x2 | Classe |\n",
    "|----|----|--------|\n",
    "| 0  | 0  | 0      |\n",
    "| 0  | 1  | 0      |\n",
    "| 1  | 0  | 0      |\n",
    "| 1  | 1  | 1      |\n",
    "\n",
    "As entradas são os valores de *x1* e *x2*. As saídas são representadas pelos valores da coluna *Classe* com o valor correspondendo ao índice de *x1*,*x2* no vetor de entrada.\n",
    "\n",
    "Temos o algoritmo básico do treinamento (para fins didáticos):\n",
    "\n",
    "- Enquanto o erro for diferente de zero\n",
    "    + Para cada registro:\n",
    "\t    * Calcula a saída com os pesos atuais.\n",
    "\t\t* Compara a saída esperada com a saída calculada, somando o erro.\n",
    "\t\t* Para cada peso da rede:\n",
    "\t\t\t+ Atualiza o peso: $peso(n+1) = peso(n) + (taxaAprendizagem \\times entrada \\times erro)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e33a58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6939555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) # matriz contendo os valores de x1,x2 em cada índice\n",
    "saidas = np.array([0, 0, 0, 1]) # valor da classe correspondente a cada índice da matriz de entrada\n",
    "pesos = np.array([0.0, 0.0])\n",
    "taxaAprendizagem = 0.1\n",
    "\n",
    "def step_function(soma):\n",
    "    if soma >= 1:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def calculaSaida(registro):\n",
    "    s = registro.dot(pesos) # Faz a aplicação da função soma\n",
    "    return step_function(s)\n",
    "\n",
    "# Treina várias vezes até minimizar o erro\n",
    "def treinar():\n",
    "    erroTotal = 1 # Inicializa com 1 só para poder entrar no laço\n",
    "    while erroTotal != 0:\n",
    "        erroTotal = 0 # Começa com a rede sem nenhum erro\n",
    "        for i in range(len(saidas)):\n",
    "            saidaCalculada = calculaSaida(np.array(entradas[i]))\n",
    "            erro = abs(saidas[i] - saidaCalculada) # abs() só para não ficar com valor negativo\n",
    "            erroTotal += erro\n",
    "            \n",
    "            # Agora é preciso atualizar os pesos\n",
    "            for j in range(len(pesos)):\n",
    "                pesos[j] = pesos[j] + (taxaAprendizagem * entradas[i][j] * erro)\n",
    "        print('Peso atualizado: ' + str(pesos[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db86acf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso atualizado: 0.1\n",
      "Peso atualizado: 0.2\n",
      "Peso atualizado: 0.30000000000000004\n",
      "Peso atualizado: 0.4\n",
      "Peso atualizado: 0.5\n",
      "Peso atualizado: 0.5\n",
      "[0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "treinar()\n",
    "print(pesos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd635123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rede Neural Treinada\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"Rede Neural Treinada\")\n",
    "print(calculaSaida(entradas[0]))\n",
    "print(calculaSaida(entradas[1]))\n",
    "print(calculaSaida(entradas[2]))\n",
    "print(calculaSaida(entradas[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a30c70",
   "metadata": {},
   "source": [
    "O treinamento em uma Rede Neural nada mais é do que encontrar um conjunto de pesos que mais se adequa aos dados, ou seja, que diminui o valor do erro.\n",
    "Quando o problema possui classes que são **linearmente separáveis**, ou seja, conseguimos separá-las com uma reta, o perceptron consegue fazer o ajuste de pesos de forma simples. Isso porque consegue fazer uma correlação entre os dados. \n",
    "\n",
    "Para problemas **não-linearmente separáveis**, uma rede neural de uma camada não consegue tratar esse tipo de problema. Para isso, são necessárias redes neurais mais complexas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd74561",
   "metadata": {},
   "source": [
    "| ![ls](img/ls.png) |\n",
    "|:--:|\n",
    "| <b>Figura 3 - Problemas Linearmente Separáveis e Não-Linearmente Separáveis.</b>|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
